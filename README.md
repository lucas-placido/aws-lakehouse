# AWS Lakehouse - Mini Projeto para PortfÃ³lio

Um mini-lakehouse completo na AWS demonstrando arquitetura moderna com **Apache Iceberg**, **Medallion Architecture** (Bronze/Silver/Gold), e orquestraÃ§Ã£o com **Step Functions** e **Lambda**.

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Sources   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  NYC TLC        â”‚â”€â”€â”
â”‚  (Open Data)    â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Lambda Functionâ”‚â”€â”€â–º IngestÃ£o AutomÃ¡tica
            â”‚  (EventBridge)  â”‚    (DiÃ¡ria Ã s 2 AM UTC)
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  S3 Bronze      â”‚â”€â”€â–º Raw Data
            â”‚  (ImutÃ¡vel)     â”‚    s3://.../bronze/nyc_tlc/
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Glue Job       â”‚â”€â”€â–º TransformaÃ§Ã£o
            â”‚  Bronzeâ†’Silver  â”‚    Limpeza, Dedup, Qualidade
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  S3 Silver      â”‚â”€â”€â–º Iceberg Tables
            â”‚  (Curado)       â”‚    ACID, Time Travel
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Glue Job       â”‚â”€â”€â–º Modelagem Dimensional
            â”‚  Silverâ†’Gold    â”‚    Fatos & DimensÃµes
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  S3 Gold        â”‚â”€â”€â–º Iceberg Tables (Analytics)
            â”‚  (Analytics)    â”‚    Pronto para BI
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Athena         â”‚â”€â”€â–º Consultas SQL
            â”‚  QuickSight     â”‚â”€â”€â–º Dashboards
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Componentes

### Infraestrutura (Terraform)
- **S3 Buckets**: Bronze, Silver, Gold, Scripts
- **Glue Databases**: bronze, silver, gold
- **Glue Jobs**: TransformaÃ§Ã£o Bronzeâ†’Silverâ†’Gold, ManutenÃ§Ã£o Iceberg
- **Lambda Function**: IngestÃ£o automÃ¡tica de dados
- **Step Functions**: OrquestraÃ§Ã£o do pipeline completo
- **EventBridge**: Agendamento (diÃ¡rio pipeline, semanal manutenÃ§Ã£o)
- **IAM Roles**: PermissÃµes adequadas para cada serviÃ§o
- **Resource Group**: Agrupa todos os recursos para visualizaÃ§Ã£o e gerenciamento centralizado

### Camadas do Lakehouse

#### ğŸ¥‰ Bronze (Raw)
- **LocalizaÃ§Ã£o**: `s3://<bucket>/bronze/nyc_tlc/<vehicle_type>/<year>/<month>/`
- **Formato**: Parquet/CSV (conforme origem)
- **CaracterÃ­sticas**: 
  - Dados imutÃ¡veis, como recebidos
  - Particionamento por tipo, ano e mÃªs
  - Versionamento habilitado

#### ğŸ¥ˆ Silver (Curated)
- **LocalizaÃ§Ã£o**: `s3://<bucket>/silver/nyc_trips/`
- **Formato**: Apache Iceberg
- **CaracterÃ­sticas**:
  - Limpeza de dados (validaÃ§Ã£o de qualidade)
  - DeduplicaÃ§Ã£o (window functions)
  - Schema padronizado (snake_case, tipos consistentes)
  - ACID transactions
  - Time travel queries
  - Particionamento otimizado

**Regras de Qualidade**:
- DuraÃ§Ã£o de viagem: 1 min â‰¤ duraÃ§Ã£o â‰¤ 3 horas
- DistÃ¢ncia: 0 < trip_distance < 100 milhas
- Valor: fare_amount â‰¥ 0

**DeduplicaÃ§Ã£o**: Por `vendor_id + pickup_datetime + dropoff_datetime`

#### ğŸ¥‡ Gold (Analytics)
- **LocalizaÃ§Ã£o**: `s3://<bucket>/gold/`
- **Formato**: Apache Iceberg
- **Modelagem**: Star Schema (Dimensional)
  - **Fato**: `fact_trips` (mÃ©tricas de viagens)
  - **DimensÃµes**: 
    - `dim_vendor` (fornecedores)
    - `dim_taxi_zone` (zonas de tÃ¡xi)

### OrquestraÃ§Ã£o

#### Step Functions Pipeline
```
IngestBronze â†’ BronzeToSilver â†’ SilverToGold â†’ Maintenance
```

**Agendamento**:
- **Pipeline DiÃ¡rio**: 3 AM UTC (via EventBridge)
- **ManutenÃ§Ã£o Semanal**: 4 AM UTC domingos (via EventBridge)

#### Lambda Function (IngestÃ£o)
- **Trigger**: EventBridge (diÃ¡rio Ã s 2 AM UTC)
- **FunÃ§Ã£o**: Copia dados do AWS Open Data Registry (NYC TLC) para S3 Bronze
- **Fonte**: `s3://nyc-tlc/trip data/`
- **Volume**: Ãšltimos 6 meses de dados (yellow + green)

## ğŸš€ Deploy Passo a Passo

### PrÃ©-requisitos

1. **AWS CLI** configurado
   ```bash
   aws configure
   ```

2. **Terraform** instalado (>= 1.0)
   ```bash
   terraform --version
   ```

3. **Python 3.9+** (para scripts locais, opcional)

4. **Conta AWS** com permissÃµes adequadas:
   - S3 (criar buckets, listar, copiar)
   - Glue (criar databases, jobs, catalog)
   - Lambda (criar functions, executar)
   - Step Functions (criar state machines)
   - IAM (criar roles, policies)
   - EventBridge (criar rules)

### Passo 1: Configurar Terraform

```bash
cd terraform
terraform init
```

### Passo 2: Deploy da Infraestrutura

```bash
terraform plan
terraform apply
```

Isso cria:
- âœ… S3 buckets (Bronze, Silver, Gold, Scripts)
- âœ… Glue databases (bronze, silver, gold)
- âœ… Glue jobs (3 jobs)
- âœ… Lambda function (ingestÃ£o)
- âœ… Step Functions state machine
- âœ… EventBridge rules (agendamento)
- âœ… IAM roles e polÃ­ticas
- âœ… Resource Group (agrupa todos os recursos)

### Passo 3: Upload dos Scripts Glue

ApÃ³s o deploy, obtenha o nome do bucket de scripts:

```bash
SCRIPTS_BUCKET=$(terraform output -raw scripts_bucket)
echo $SCRIPTS_BUCKET
```

Upload dos scripts:

```bash
# Upload scripts Glue
aws s3 cp glue-jobs/nyc_tlc_to_silver.py s3://$SCRIPTS_BUCKET/glue-jobs/
aws s3 cp glue-jobs/nyc_trips_gold.py s3://$SCRIPTS_BUCKET/glue-jobs/
aws s3 cp glue-jobs/iceberg_maintenance.py s3://$SCRIPTS_BUCKET/glue-jobs/
```

### Passo 4: Executar IngestÃ£o Inicial

**OpÃ§Ã£o 1: Via Lambda (AutomÃ¡tico)**
- A Lambda executa automaticamente Ã s 2 AM UTC via EventBridge
- Ou invoque manualmente:

```bash
LAMBDA_ARN=$(terraform output -raw lambda_function_arn)
aws lambda invoke --function-name $LAMBDA_ARN response.json
```

**OpÃ§Ã£o 2: Via Step Functions (Pipeline Completo)**
```bash
SM_ARN=$(terraform output -raw stepfunctions_state_machine_arn)
aws stepfunctions start-execution --state-machine-arn $SM_ARN
```

### Passo 5: Verificar Dados

#### Verificar S3 Bronze
```bash
BRONZE_BUCKET=$(terraform output -raw bronze_bucket)
aws s3 ls s3://$BRONZE_BUCKET/bronze/nyc_tlc/ --recursive
```

#### Verificar Glue Tables
```bash
# Listar databases
aws glue get-databases

# Listar tabelas no Silver
aws glue get-tables --database-name silver

# Listar tabelas no Gold
aws glue get-tables --database-name gold
```

#### Visualizar Resource Group
Todos os recursos estÃ£o agrupados em um **Resource Group** para fÃ¡cil visualizaÃ§Ã£o:

1. Acesse o **AWS Resource Groups Console** (https://console.aws.amazon.com/resource-groups)
2. Procure por `lakehouse-resources`
3. VocÃª verÃ¡ todos os recursos do projeto agrupados:
   - S3 buckets
   - Glue databases e jobs
   - Lambda functions
   - Step Functions
   - IAM roles
   - EventBridge rules

Ou via CLI:
```bash
RESOURCE_GROUP_NAME=$(terraform output -raw resource_group_name)
aws resource-groups get-group --group-name $RESOURCE_GROUP_NAME --profile gudy
```

#### Consultar com Athena

1. Abra **Amazon Athena Console**
2. Selecione database `silver` ou `gold`
3. Execute queries:

```sql
-- Contar registros Silver
SELECT COUNT(*) FROM silver.nyc_trips;

-- Consulta Gold (Fato + DimensÃµes)
SELECT 
  d.vendor_name,
  COUNT(*) as total_trips,
  AVG(f.fare_amount) as avg_fare,
  SUM(f.total_amount) as total_revenue
FROM gold.fact_trips f
JOIN gold.dim_vendor d ON f.vendor_id = d.vendor_id
GROUP BY d.vendor_name
ORDER BY total_revenue DESC;

-- Top 10 zonas de pickup
SELECT 
  dz.zone_name,
  COUNT(*) as total_trips,
  AVG(f.fare_amount) as avg_fare
FROM gold.fact_trips f
JOIN gold.dim_taxi_zone dz ON f.pickup_zone_id = dz.zone_id
GROUP BY dz.zone_name
ORDER BY total_trips DESC
LIMIT 10;
```

## ğŸ“Š Fluxo de Dados Completo

### 1. IngestÃ£o (Lambda)

**Fonte**: AWS Open Data Registry - NYC TLC Trip Records
- **Bucket**: `s3://nyc-tlc/`
- **Formato**: Parquet/CSV
- **Dados**: Yellow + Green taxis
- **PerÃ­odo**: Ãšltimos 6 meses

**Processo**:
1. Lambda Ã© acionada via EventBridge (diÃ¡rio Ã s 2 AM UTC)
2. Lista arquivos do perÃ­odo no bucket pÃºblico
3. Copia para `s3://<bronze-bucket>/bronze/nyc_tlc/<type>/<year>/<month>/`
4. Verifica se arquivo jÃ¡ existe (idempotÃªncia)

### 2. TransformaÃ§Ã£o Bronze â†’ Silver (Glue Job)

**Job**: `nyc-tlc-bronze-to-silver`

**Processo**:
1. **Leitura**: LÃª dados do Bronze (Parquet/CSV)
2. **Limpeza**:
   - ConversÃ£o de tipos (timestamp, integer, double)
   - PadronizaÃ§Ã£o de nomes (snake_case)
   - ValidaÃ§Ã£o de qualidade:
     - DuraÃ§Ã£o: 1 min â‰¤ duraÃ§Ã£o â‰¤ 3h
     - DistÃ¢ncia: 0 < distance < 100
     - Valor: fare_amount â‰¥ 0
3. **DeduplicaÃ§Ã£o**: Window function por `vendor_id + pickup_datetime + dropoff_datetime`
4. **Escrita**: Cria/atualiza tabela Iceberg no Silver
   - Particionamento: `pickup_date` (ano/mÃªs/dia)
   - Formato: Apache Iceberg
   - ACID transactions habilitadas

**Schema Silver**:
```sql
CREATE TABLE silver.nyc_trips (
  vendor_id STRING,
  pickup_datetime TIMESTAMP,
  dropoff_datetime TIMESTAMP,
  passenger_count INT,
  trip_distance DOUBLE,
  pickup_location_id INT,
  dropoff_location_id INT,
  payment_type INT,
  fare_amount DOUBLE,
  tip_amount DOUBLE,
  total_amount DOUBLE,
  pickup_date DATE,
  pickup_year INT,
  pickup_month INT,
  pickup_day INT
)
USING ICEBERG
PARTITIONED BY (pickup_date)
```

### 3. Modelagem Silver â†’ Gold (Glue Job)

**Job**: `nyc-trips-silver-to-gold`

**Processo**:
1. **Leitura**: LÃª tabela `silver.nyc_trips`
2. **DimensÃµes**:
   - `dim_vendor`: Mapeia vendor_id para nome
   - `dim_taxi_zone`: Zonas de pickup/dropoff
3. **Fato**: `fact_trips`
   - MÃ©tricas: trip_distance, fare_amount, tip_amount, total_amount
   - DimensÃµes: vendor_id, pickup_zone_id, dropoff_zone_id
   - Calculados: trip_duration_seconds, fare_per_mile
4. **Escrita**: Cria tabelas Iceberg no Gold

**Schema Gold**:

```sql
-- DimensÃ£o Vendor
CREATE TABLE gold.dim_vendor (
  vendor_id STRING,
  vendor_name STRING
)
USING ICEBERG;

-- DimensÃ£o Taxi Zone
CREATE TABLE gold.dim_taxi_zone (
  zone_id INT,
  zone_name STRING
)
USING ICEBERG;

-- Fato Trips
CREATE TABLE gold.fact_trips (
  vendor_id STRING,
  pickup_zone_id INT,
  dropoff_zone_id INT,
  pickup_datetime TIMESTAMP,
  dropoff_datetime TIMESTAMP,
  pickup_date DATE,
  trip_distance DOUBLE,
  fare_amount DOUBLE,
  tip_amount DOUBLE,
  total_amount DOUBLE,
  passenger_count INT,
  payment_type INT,
  trip_duration_seconds INT,
  fare_per_mile DOUBLE
)
USING ICEBERG
PARTITIONED BY (pickup_date);
```

### 4. ManutenÃ§Ã£o Iceberg (Glue Job)

**Job**: `iceberg-maintenance`

**Processo** (executado semanalmente):
1. **Expire Snapshots**: Remove snapshots antigos (retenÃ§Ã£o: 7 dias)
2. **Compaction**: Compacta arquivos pequenos (target: 256MB)
3. **Remove Orphan Files**: Remove arquivos Ã³rfÃ£os

**BenefÃ­cios**:
- Reduz custos de storage
- Melhora performance de queries
- Otimiza leitura (menos arquivos)

## ğŸ”§ ConfiguraÃ§Ã£o e CustomizaÃ§Ã£o

### VariÃ¡veis Terraform

Edite `terraform/variables.tf`:

```hcl
variable "aws_region" {
  default = "us-east-1"  # Altere para sua regiÃ£o
}
```

### Agendamento

Edite `terraform/stepfunctions.tf` para alterar horÃ¡rios:

```hcl
# Pipeline diÃ¡rio
schedule_expression = "cron(0 3 * * ? *)"  # 3 AM UTC

# ManutenÃ§Ã£o semanal
schedule_expression = "cron(0 4 ? * SUN *)"  # 4 AM UTC domingos
```

### Volume de Dados

Edite `lambda/nyc_tlc_ingest.py`:

```python
MONTHS_TO_INGEST = 6  # Altere para mais/menos meses
VEHICLE_TYPES = ["yellow", "green"]  # Adicione "fhv" se necessÃ¡rio
```

## ğŸ’° Custos Estimados

**MVP Mensal**: ~$10-20

**Detalhamento**:
- **S3**: ~$2-5 (dependendo do volume)
- **Glue**: ~$5-10 (jobs on-demand, G.1X)
- **Lambda**: ~$0.10 (1 execuÃ§Ã£o/dia, 5min)
- **Step Functions**: ~$0.10 (1 execuÃ§Ã£o/dia)
- **Athena**: ~$1-5 (consultas, otimizado com partiÃ§Ãµes)
- **EventBridge**: Gratuito (atÃ© 1M eventos/mÃªs)

**OtimizaÃ§Ãµes**:
- Lifecycle policies (transiÃ§Ã£o para IA apÃ³s 30 dias)
- Compaction Iceberg (arquivos maiores = menos requests)
- Particionamento adequado (reduz dados lidos)

## ğŸ¯ Diferenciais do Projeto

### Arquitetura Moderna
- âœ… **Apache Iceberg**: ACID transactions, time travel, schema evolution
- âœ… **Medallion Architecture**: Bronze â†’ Silver â†’ Gold
- âœ… **Serverless**: Lambda + Step Functions (sem servidores)

### Boas PrÃ¡ticas
- âœ… **IaC**: Terraform (infraestrutura como cÃ³digo)
- âœ… **Qualidade de Dados**: ValidaÃ§Ã£o e deduplicaÃ§Ã£o
- âœ… **OrquestraÃ§Ã£o**: Step Functions com retry logic
- âœ… **Agendamento**: EventBridge (cron expressions)
- âœ… **GovernanÃ§a**: IAM roles com least privilege

### Pronto para ProduÃ§Ã£o
- âœ… **IdempotÃªncia**: Verifica se arquivo jÃ¡ existe antes de copiar
- âœ… **Error Handling**: Retry logic no Step Functions
- âœ… **Monitoramento**: CloudWatch logs habilitados
- âœ… **ManutenÃ§Ã£o**: Compaction e expire snapshots automÃ¡ticos

## ğŸ“š ReferÃªncias

- [AWS Open Data Registry - NYC TLC](https://registry.opendata.aws/nyc-tlc-trip-records-pds/)
- [Apache Iceberg on AWS](https://docs.aws.amazon.com/athena/latest/ug/querying-iceberg.html)
- [AWS Glue Best Practices](https://docs.aws.amazon.com/glue/latest/dg/best-practices.html)
- [Step Functions](https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html)

## ğŸ› Troubleshooting

### Lambda nÃ£o executa
- Verifique CloudWatch Logs: `/aws/lambda/lakehouse-nyc-tlc-ingest`
- Verifique permissÃµes IAM do Lambda
- Verifique se EventBridge rule estÃ¡ habilitada

### Glue Job falha
- Verifique logs no CloudWatch: `/aws-glue/jobs/output`
- Verifique se scripts estÃ£o no S3
- Verifique permissÃµes IAM do Glue

### Tabela Iceberg nÃ£o encontrada
- Execute o job Bronzeâ†’Silver primeiro
- Verifique se database existe: `aws glue get-database --name silver`
- Verifique logs do Glue job

### Step Functions falha
- Verifique execuÃ§Ã£o no console Step Functions
- Verifique permissÃµes IAM
- Verifique se jobs Glue existem

## ğŸ“ Estrutura do Projeto

```
aws-lakehouse/
â”œâ”€â”€ terraform/              # Infraestrutura como CÃ³digo
â”‚   â”œâ”€â”€ main.tf            # S3 buckets
â”‚   â”œâ”€â”€ glue.tf            # Glue databases e jobs
â”‚   â”œâ”€â”€ lambda.tf          # Lambda function
â”‚   â”œâ”€â”€ stepfunctions.tf   # Step Functions e EventBridge
â”‚   â”œâ”€â”€ variables.tf       # VariÃ¡veis
â”‚   â””â”€â”€ outputs.tf         # Outputs
â”œâ”€â”€ lambda/                # Lambda functions
â”‚   â””â”€â”€ nyc_tlc_ingest.py  # IngestÃ£o de dados
â”œâ”€â”€ glue-jobs/             # Glue jobs
â”‚   â”œâ”€â”€ nyc_tlc_to_silver.py      # Bronze â†’ Silver
â”‚   â”œâ”€â”€ nyc_trips_gold.py         # Silver â†’ Gold
â”‚   â””â”€â”€ iceberg_maintenance.py    # ManutenÃ§Ã£o
â””â”€â”€ README.md              # Este arquivo
```

## ğŸš€ PrÃ³ximos Passos

1. âœ… Deploy da infraestrutura
2. âœ… Upload dos scripts Glue
3. âœ… Executar ingestÃ£o inicial
4. âœ… Verificar dados no Athena
5. âœ… Criar dashboards no QuickSight (opcional)
6. âœ… Monitorar custos no Cost Explorer

## ğŸ“„ LicenÃ§a

MIT
